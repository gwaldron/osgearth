/* -*-c++-*- */
/* osgEarth - Geospatial SDK for OpenSceneGraph
 * Copyright 2020 Pelican Mapping
 * http://osgearth.org
 *
 * osgEarth is free software; you can redistribute it and/or modify
 * it under the terms of the GNU Lesser General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>
 */
#ifndef OSGEARTH_THREADING_UTILS_H
#define OSGEARTH_THREADING_UTILS_H 1

#include <osgEarth/Common>
#include <osg/OperationThread>
#include <atomic>
#include <functional>
#include <mutex>
#include <condition_variable>
#include <vector>
#include <unordered_map>
#include <queue>
#include <thread>
#include <future>
#include <type_traits>

#define USE_CUSTOM_READ_WRITE_LOCK 1

namespace osgDB {
    class Options;
}

// to include the file and line as the mutex name
#define OE_MUTEX_NAME __FILE__ ":" OE_STRINGIFY(__LINE__)

namespace osgEarth { namespace Threading
{
    //! C++ BasicLockable requirement
    class BasicLockable
    {
    public:
        virtual void lock() =0;
        virtual void unlock() = 0;
    };

    //! C++ Lockable requirement
    class Lockable : public BasicLockable
    {
    public:
        virtual bool try_lock() =0;
    };

    /**
     * A normal mutex
     */
    class OSGEARTH_EXPORT Mutex : public Lockable
    {
    public:
        Mutex();
        Mutex(const std::string& name, const char* file=nullptr, std::uint32_t line=0);
        //! Do not permit copy constructor on Mutex
        Mutex(const Mutex& copy) = delete;
        ~Mutex();

        //! Explicitly block the copy operator
        Mutex& operator=(const Mutex& copy) = delete;

        void lock() override;
        void unlock() override;
        bool try_lock() override;

        void setName(const std::string& name);

    private:
        std::string _name;
        void* _handle;
        void* _metricsData;
    };

    typedef std::lock_guard<BasicLockable> ScopedMutexLock;

    /**
     * A recursive mutex
     */
    class OSGEARTH_EXPORT RecursiveMutex : public Lockable
    {
    public:
        RecursiveMutex();
        RecursiveMutex(const std::string& name, const char* file=nullptr, std::uint32_t line=0);
        ~RecursiveMutex();

        //! Enable or disable this mutex. Don't call this while threads are running.
        void disable();

        void lock() override;
        void unlock() override;
        bool try_lock() override;

        void setName(const std::string& name);

    private:
        bool _enabled;
        std::string _name;
        void* _handle;
        void* _metricsData;
    };

    typedef std::lock_guard<RecursiveMutex> ScopedRecursiveMutexLock;

    /**
     * Gets the unique ID of the running thread.
     */
    extern OSGEARTH_EXPORT unsigned getCurrentThreadId();

    /**
    * Pure interface for an object that can be canceled.
    */
    class Cancelable
    {
    public:
        virtual bool isCanceled() const = 0;
    };

    /**
     * Event with a binary signaled state, for multi-threaded sychronization.
     *
     * The event has two states:
     *  "set" means that a call to wait() will not block;
     *  "unset" means that calls to wait() will block until another thread calls set().
     *
     * The event starts out unset.
     *
     * Typical usage: Thread A creates Thread B to run asynchronous code. Thread A
     * then calls wait(), which blocks Thread A. When Thread B is finished, it calls
     * set(). Thread A then wakes up and continues execution.
     *
     * NOTE: ALL waiting threads will wake up when the Event is cleared.
     */
    class OSGEARTH_EXPORT Event
    {
    public:
        //! Construct a new event
        Event();

        Event(const std::string& name);

        //! DTOR
        ~Event();

        //! Block until the event is set, then return true if set, false on error.
        bool wait();

        //! Like wait(), but also returns false on timeout.
        bool wait(unsigned timeout_ms);

        //! Like wait(), but resets the state before returning.
        bool waitAndReset();

        //! Set the event state, causing any waiters to unblock.
        void set();

        //! Reset (unset) the event state; new waiters will block until set() is called.
        void reset();

        //! Whether the event state is set (waiters will not block).
        inline bool isSet() const { return _set; }

        void setName(const std::string& name);

    protected:
        Mutex _m;
        std::condition_variable_any _cond;
        bool _set;
    };

    /** Wraps an Event in a Referenced. */
    class OSGEARTH_EXPORT RefEvent : public Event, public osg::Referenced
    {
    public:
        RefEvent() : Event() , osg::Referenced() { }
        RefEvent(const std::string& name) : Event(name), osg::Referenced() { }
    };

    /**
     * Future is the consumer-side interface to an asynchronous operation.
     *
     * Usage:
     *   Producer (usually an asynchronous function call) creates a Promise<Object>
     *   and immediately returns promise.getFuture(). The Consumer then performs other
     *   work, and eventually (or immediately) called Future.get() or Future.release().
     *   Either call will block until the asynchronous operation is complete and the
     *   result in Future is available.
     */
    template<typename T>
    class Future : public Cancelable
    {
    public:
        typedef std::function<void(T*)> Callback;

    private:
        // internal structure to track referenced to the result
        struct RefPtrRef : public osg::Referenced {
            RefPtrRef(T* obj = 0L) : _obj(obj) { }
            osg::ref_ptr<T> _obj;
            std::vector<Callback> _callbacks;
            std::mutex _callbacksMutex;
        };

    public:
        //! Blank CTOR
        Future() {
            _ev = new RefEvent();
            _objRef = new RefPtrRef();
        }

        Future(const std::string& name) {
            _ev = new RefEvent(name);
            _objRef = new RefPtrRef();
        }

        //! Copy CTOR
        Future(const Future& rhs) :
            _ev(rhs._ev),
            _objRef(rhs._objRef) { }

        Future<T>& operator = (const Future<T>& rhs) {
            _ev = rhs._ev;
            _objRef = rhs._objRef;
            return *this;
        }

        //! True if the promise was resolved and a result if available.
        bool isAvailable() const {
            return _ev->isSet();
        }

        //! True if the Promise that generated this Future no longer exists.
        bool isAbandoned() const {
            return _objRef->referenceCount() == 1;
        }

        bool isCanceled() const override {
            return isAbandoned();
        }

        //! The result value; blocks until it is available (or abandonded) and then returns it.
        T* get() {
            while(!_ev->wait(1000u))
                if (isAbandoned()) return 0L;
            return _objRef->_obj.get();
        }

        T* get(const Cancelable* cancelable) {
            while(!_ev->wait(1000u)) {
                if (isAbandoned()) return 0L;
                if (cancelable && cancelable->isCanceled()) return 0L;
            }
            return _objRef->_obj.get();
        }

        //! The result value; blocks until available (or abandoned) and returns it; then resets to initial state.
        T* release() {
            while(!_ev->wait(1000u))
                if (isAbandoned()) return 0L;
            T* out = _objRef->_obj.release();
            _ev->reset();
            return out;
        }

        T* release(const Cancelable* cancelable) {
            while(!_ev->wait(1000u)) {
                if (isAbandoned()) return 0L;
                if (cancelable && cancelable->isCanceled()) return 0L;
            }
            T* out = _objRef->_obj.release();
            _ev->reset();
            return out;
        }

        Future<T>& then(std::function<void(T*)>& func) {
            std::unique_lock<std::mutex> lock(_objRef->_callbacksMutex);
            if (_ev->isSet())
                func(_objRef->_obj.get());
            else
                _objRef->_callbacks.push_back(func);
            return *this;
        }

    private:
        osg::ref_ptr<RefEvent> _ev;
        osg::ref_ptr<RefPtrRef> _objRef;
        template<typename U> friend class Promise;
    };

    /**
     * Promise is the producer-side interface to an asynchronous operation.
     *
     * Usage: The code that initiates an asychronous operation creates a Promise
     *   object, dispatches the asynchronous code, and immediately returns
     *   Promise.getFuture(). The caller can then call future.get() to block until
     *   the result is available.
     */
    template<typename T>
    class Promise : public Cancelable
    {
    public:
        Promise() { }

        Promise(const std::string& name) : _future(name) { }

        //! This promise's future result.
        Future<T> getFuture() const { return _future; }

        //! Resolve (fulfill) the promise with the provided result value.
        void resolve(T* value) {
            _future._objRef->_obj = value;
            {
                std::unique_lock<std::mutex> lock(_future._objRef->_callbacksMutex);
                for(auto& f : _future._objRef->_callbacks)
                    f(value);
            }
            _future._ev->set();
        }

        //! True if the promise is resolved and the Future holds a valid result.
        bool isResolved() const {
            return _future._ev->isSet();
        }

        //! True is there are no Future objects waiting on this Promise.
        bool isAbandoned() const {
            return _future._objRef->referenceCount() == 1;
        }

        bool isCanceled() const override {
            return isAbandoned();
        }

    private:
        Future<T> _future;
    };

    /**
     * Convenience base class for representing a Result object that may be
     * synchronous or asynchronous, depending on which constructor you use.
     */
    template<typename T>
    class FutureResult
    {
    public:
        bool isReady() const { return _future.isAvailable() || _future.isAbandoned(); }

    protected:
        //! Asynchronous constructor
        FutureResult(Future<T> f) : _future(f) { }

        //! Immediate synchronous resolve constructor
        FutureResult(T* data) {
            Promise<T> p;
            _future = p.getFuture();
            p.resolve(data);
        }

        Future<T> _future;
    };


    /**
    * Mutex that locks on a per-object basis
    */
    template<typename T>
    class Gate
    {
    public:
        Gate() { }

        Gate(const std::string& name) : _m(name) { }

        inline void lock(T key) {
            std::unique_lock<Mutex> lock(_m);
            while(_users[key] > 0)
                _unlocked.wait(lock);
            ++_users[key];
        }

        inline void unlock(T key) {
            std::unique_lock<Mutex> lock(_m);
            --_users[key];
            if (_users[key] == 0) {
                _users.erase(key);
                _unlocked.notify_all();
            }
        }

        inline void setName(const std::string& name) {
            _m.setName(name);
        }

    private:
        Mutex _m;
        std::condition_variable_any _unlocked;
        std::unordered_map<T, int> _users;
    };

    template<typename T>
    struct ScopedGate {
        Gate<T>& _gate;
        T _key;
        ScopedGate(Gate<T>& gate, T key) : _gate(gate), _key(key) { _gate.lock(key); }
        ~ScopedGate() { _gate.unlock(_key); }
    };

    /**
     * Mutex that allows many simultaneous readers but only one writer
     */
    template<typename T>
    class ReadWrite
    {
    public:
        ReadWrite() :
            _readers(0u), _writers(0u) { }

        ReadWrite(const std::string& name) :
            _m(name), _readers(0u), _writers(0u) { }

        void read_lock() {
            std::unique_lock<T> lock(_m);
            while (_writers > 0)
                _unlocked.wait(lock);
            ++_readers;
        }

        void read_unlock() {
            std::unique_lock<T> lock(_m);
            --_readers;
            if (_readers == 0)
                _unlocked.notify_all();
        }

        void write_lock() {
            std::unique_lock<T> lock(_m);
            while (_writers > 0 || _readers > 0)
                _unlocked.wait(lock);
            ++_writers;
        }

        void write_unlock() {
            std::unique_lock<T> lock(_m);
            _writers = 0;
            _unlocked.notify_all();
        }

        void setName(const std::string& name) {
            _m.setName(name);
        }

    private:
        T _m;
        std::condition_variable_any _unlocked;
        unsigned _writers;
        unsigned _readers;
    };

    template<typename T>
    struct ScopedWrite {
        ScopedWrite( ReadWrite<T>& lock ) : _lock(lock) { _lock.write_lock(); }
        ~ScopedWrite() { _lock.write_unlock(); }
    private:
        ReadWrite<T>& _lock;
    };

    template<typename T>
    struct ScopedRead {
        ScopedRead( ReadWrite<T>& lock ) : _lock(lock) { _lock.read_lock(); }
        ~ScopedRead() { _lock.read_unlock(); }
    private:
        ReadWrite<T>& _lock;
    };

    typedef ReadWrite<Mutex> ReadWriteMutex;
    typedef ReadWrite<RecursiveMutex> ReadWriteRecursiveMutex;
    typedef ScopedRead<Mutex> ScopedReadLock;
    typedef ScopedWrite<Mutex> ScopedWriteLock;
    typedef ScopedRead<RecursiveMutex> ScopedRecursiveReadLock;
    typedef ScopedWrite<RecursiveMutex> ScopedRecursiveWriteLock;

    /**
     * A ThreadPool that contains a work queue and one or more
     * threads that process the operations on the queue.
     */
    class OSGEARTH_EXPORT ThreadPool : public osg::Referenced
    {
    public:
        //! Allocate a new pool with "numThreads" threads.
        ThreadPool(
            unsigned numThreads =2u);

        //! Allocate a new pool with "numThreads" threads
        ThreadPool(
            const std::string& name,
            unsigned numThreads =2u);

        //! Destroy
        ~ThreadPool();

        //! Run an asynchronous operation in this thread pool.
        void run(osg::Operation*);

        //! How many operations are queued up?
        unsigned getNumOperationsInQueue() const;

        //! Store/retrieve thread pool stored in an options structure
        void put(class osgDB::Options*);
        static osg::ref_ptr<ThreadPool> get(const class osgDB::Options*);

    private:
        void startThreads();
        void stopThreads();

        // thread name
        std::string _name;

        // queued operations to run asynchronously
        typedef std::queue<osg::ref_ptr<osg::Operation> > Queue;
        Queue _queue;
        // protect access to the queue
        Mutex _queueMutex;
        // number of concurrent threads in the pool
        unsigned int _numThreads;
        // thread waiter block
        std::condition_variable_any _block;
        // set to true when threads should exit
        bool _done;
        // threads in the pool
        std::vector<std::thread> _threads;
    };

    /**
     * Simple convenience construct to make another type "lockable"
     * as long as it has a default constructor
     */
    template<typename T>
    struct Mutexed : public T, public BasicLockable {
        Mutexed() : T() { }
        Mutexed(const std::string& name) : _lockable_mutex(name), T() { }
        void setName(const std::string& name) { _lockable_mutex.setName(name); }
        void lock() { _lockable_mutex.lock(); }
        void lock() const { _lockable_mutex.lock(); }
        void unlock() { _lockable_mutex.unlock(); }
        void unlock() const { _lockable_mutex.unlock(); }
        Mutex& mutex() const { return _lockable_mutex; }
    private:
        mutable Mutex _lockable_mutex;
    };


    /**
     * Simple atomic counter that increments an atomic
     * when entering a scope and decrements it upon exiting the scope
     */
    struct ScopedAtomicCounter
    {
        std::atomic_int& _a;
        ScopedAtomicCounter(std::atomic_int& a) : _a(a) { ++_a; }
        ~ScopedAtomicCounter() { --_a; }
    };

    //! Sets the name of the curent thread
    extern OSGEARTH_EXPORT void setThreadName(const std::string& name);

    //! Sets the thread name with details when scoped
    struct ScopedThreadName
    {
        std::string _base;
        ScopedThreadName(const std::string& base, const std::string& detail) : 
            _base(base)
        {
            setThreadName(base + "(" + detail + ")");
        }
        ~ScopedThreadName()
        {
            setThreadName(_base);
        }
    };

    // std::invoke workaround for c++11
    // https://stackoverflow.com/questions/38288042/c11-14-invoke-workaround
    template<typename Fn, typename... Args>
    constexpr auto cpp11invoke(Fn&& f, Args&&... args)
        noexcept(noexcept(std::forward<Fn>(f)(std::forward<Args>(args)...)))
        -> typename std::result_of<Fn(Args...)>::type
    {
        return std::forward<Fn>(f)(std::forward<Args>(args)...);
    }

    /**
     * Task that you can schedule to run in the background.
     * A Job is single-use. Do not schedule the same Job more than
     * once - results are undefined.
     *
     * Example usage:
     *
     *   struct ReturnValue : public osg::Referenced {
     *       int _result;
     *       ReturnValue(int x) : _result(x);
     *   };
     *
     *   typedef Job<ReturnValue> AddNumbersJob;
     *   ...
     *
     *   int a = 10, b = 20;
     *   AddNumbersJob job( [a, b](Cancelable* progress) {
     *       if (progress->isCanceled())
     *           return nullptr;
     *       else
     *           return new ReturnValue(a + b);
     *   });
     *
     *   AddNumbersJob::Result result = job.schedule();
     *
     *   // later...
     *
     *   if (result.isAvailable()) {
     *       std::cout << "Answer = " << result.get()->_result << std::endl;
     *   }
     *   else if (result.isAbandoned()) {
     *       // task was canceled
     *   }
     */
    template<typename RESULT_TYPE>
    class Job
    {
    public:
        typedef Future<RESULT_TYPE> Result;

        //! Construct a new job
        //! @param func Function to invoke
        //! @param args Arguments to pass to "func". (Func must also take a final
        //!             Cancelable* argument)
        template<typename FUNC, typename...ARGS>
        Job(FUNC&& func, ARGS&&... args)
        {
            Promise<RESULT_TYPE> promise;
            _future = promise.getFuture();

            _delegate = [promise, func, args...]() mutable
            {
                if (!promise.isAbandoned())
                {
                    promise.resolve(cpp11invoke(func, args..., &promise));
                }
            };
        }

        //! Schedule this job to run asynchronously.
        //! A Job is one-use-only; scheduling the same Job object more
        //! than once will have undefined results.
        //!
        //! @return A future result. You can check the result periodically
        //!         to see whether it is available or has been adandoned.
        inline Result schedule();
        inline Result schedule(const std::string& arena);

    private:
        std::function<void()> _delegate;
        Future<RESULT_TYPE> _future;
        friend class JobArena;
    };

    /**
     * Schedules asynchronous tasks on a thread pool.
     * You usually don't need to use this class directly.
     * Use Job::schedule() to queue a new job.
     */
    class OSGEARTH_EXPORT JobArena : public osg::Referenced
    {
    public:
        //! Allocate a new arena with "concurrency" threads.
        JobArena(
            const std::string& name,
            unsigned concurrency);

        //! Destroy
        ~JobArena();

        //! Schedule an asynchronous task.
        //! @param job Job to schedule
        //! @return The future result of the task, which you must store
        //!         otherwise the task will automatically cancel
        template<typename RESULT_TYPE>
        static
        Future<RESULT_TYPE>
        schedule(Job<RESULT_TYPE>& job, const std::string& name) {
            return arena(name)->scheduleJob(job);
        }

        //! Sets the concurrency of a named arena
        static void setSize(
            const std::string& name,
            unsigned numThreads);

    private:

        //! Access the named arena
        static JobArena* arena(const std::string& name);

        void startThreads();

        void stopThreads();

        template<typename RESULT_TYPE>
        Future<RESULT_TYPE>
        scheduleJob(Job<RESULT_TYPE>& job) {
            std::unique_lock<Mutex> lock(_queueMutex);
            Future<RESULT_TYPE> result = std::move(job._future);
            std::function<void()>& delegate = job._delegate;
            _queue.emplace_back([delegate] { delegate(); });
            _block.notify_all();
            return result;
        }

        // pool name
        std::string _name;
        // queued operations to run asynchronously
        typedef std::deque<std::function<void()>> Queue;
        Queue _queue;
        // protect access to the queue
        Mutex _queueMutex;
        // number of concurrent threads in the pool
        unsigned _numThreads;
        // thread waiter block
        std::condition_variable_any _block;
        // set to true when threads should exit
        bool _done;
        // threads in the pool
        std::vector<std::thread> _threads;

        static Mutex _arenas_mutex;
        static std::unordered_map<std::string, unsigned> _arenaSizes;
        static std::unordered_map<std::string, osg::ref_ptr<JobArena>> _arenas;
    };

    template<typename RESULT_TYPE>
    Future<RESULT_TYPE> Job<RESULT_TYPE>::schedule() {
        return JobArena::schedule(*this, "");
    }

    template<typename RESULT_TYPE>
    Future<RESULT_TYPE> Job<RESULT_TYPE>::schedule(const std::string& arena) {
        return JobArena::schedule(*this, arena);
    }

} } // namepsace osgEarth::Threading

#define OE_THREAD_NAME(name) osgEarth::Threading::setThreadName(name);

#define OE_SCOPED_THREAD_NAME(base,name) osgEarth::Threading::ScopedThreadName _scoped_threadName(base,name);

#endif // OSGEARTH_THREADING_UTILS_H
