/* -*-c++-*- */
/* osgEarth - Geospatial SDK for OpenSceneGraph
 * Copyright 2020 Pelican Mapping
 * http://osgearth.org
 *
 * osgEarth is free software; you can redistribute it and/or modify
 * it under the terms of the GNU Lesser General Public License as published by
 * the Free Software Foundation; either version 2 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>
 */
#ifndef OSGEARTH_THREADING_UTILS_H
#define OSGEARTH_THREADING_UTILS_H 1

#include <osgEarth/Common>
#include <atomic>
#include <functional>
#include <mutex>
#include <condition_variable>
#include <vector>
#include <unordered_map>
#include <queue>
#include <thread>
#include <future>
#include <type_traits>

#define USE_CUSTOM_READ_WRITE_LOCK 1

namespace osg {
    class Operation;
}
namespace osgDB {
    class Options;
}

// to include the file and line as the mutex name
#define OE_MUTEX_NAME __FILE__ ":" OE_STRINGIFY(__LINE__)

namespace osgEarth { namespace Threading
{
    //! C++ BasicLockable requirement
    class BasicLockable
    {
    public:
        virtual void lock() =0;
        virtual void unlock() = 0;
    };

    //! C++ Lockable requirement
    class Lockable : public BasicLockable
    {
    public:
        virtual bool try_lock() =0;
    };

    /**
     * A normal mutex
     */
    class OSGEARTH_EXPORT Mutex : public Lockable
    {
    public:
        Mutex();
        Mutex(const std::string& name, const char* file=nullptr, std::uint32_t line=0);
        //! Do not permit copy constructor on Mutex
        Mutex(const Mutex& copy) = delete;
        ~Mutex();

        //! Explicitly block the copy operator
        Mutex& operator=(const Mutex& copy) = delete;

        void lock() override;
        void unlock() override;
        bool try_lock() override;

        void setName(const std::string& name);

    private:
        std::string _name;
        void* _handle;
        void* _metricsData;
    };

    typedef std::lock_guard<BasicLockable> ScopedMutexLock;

    /**
     * A recursive mutex
     */
    class OSGEARTH_EXPORT RecursiveMutex : public Lockable
    {
    public:
        RecursiveMutex();
        RecursiveMutex(const std::string& name, const char* file=nullptr, std::uint32_t line=0);
        ~RecursiveMutex();

        //! Enable or disable this mutex. Don't call this while threads are running.
        void disable();

        void lock() override;
        void unlock() override;
        bool try_lock() override;

        void setName(const std::string& name);

    private:
        bool _enabled;
        std::string _name;
        void* _handle;
        void* _metricsData;
    };

    typedef std::lock_guard<RecursiveMutex> ScopedRecursiveMutexLock;

    /**
     * Gets the approximate number of available threading contexts.
     * Result is guaranteed to be greater than zero
     */
    extern OSGEARTH_EXPORT unsigned getConcurrency();

    /**
     * Gets the unique ID of the running thread.
     */
    extern OSGEARTH_EXPORT unsigned getCurrentThreadId();

    /**
    * Pure interface for an object that can be canceled.
    */
    class Cancelable
    {
    public:
        virtual bool isCanceled() const = 0;
    };

    /**
     * Event with a binary signaled state, for multi-threaded sychronization.
     *
     * The event has two states:
     *  "set" means that a call to wait() will not block;
     *  "unset" means that calls to wait() will block until another thread calls set().
     *
     * The event starts out unset.
     *
     * Typical usage: Thread A creates Thread B to run asynchronous code. Thread A
     * then calls wait(), which blocks Thread A. When Thread B is finished, it calls
     * set(). Thread A then wakes up and continues execution.
     *
     * NOTE: ALL waiting threads will wake up when the Event is cleared.
     */
    class OSGEARTH_EXPORT Event
    {
    public:
        //! Construct a new event
        Event();

        Event(const std::string& name);

        //! DTOR
        ~Event();

        //! Block until the event is set, then return true if set, false on error.
        bool wait();

        //! Like wait(), but also returns false on timeout.
        bool wait(unsigned timeout_ms);

        //! Like wait(), but resets the state before returning.
        bool waitAndReset();

        //! Set the event state, causing any waiters to unblock.
        void set();

        //! Reset (unset) the event state; new waiters will block until set() is called.
        void reset();

        //! Whether the event state is set (waiters will not block).
        inline bool isSet() const { return _set; }

        void setName(const std::string& name);

    protected:
        Mutex _m;
        std::condition_variable_any _cond;
        bool _set;
    };

    /**
     * Future is the consumer-side interface to an asynchronous operation.
     *
     * Usage:
     *   Producer (usually an asynchronous function call) creates a Promise<Object>
     *   and immediately returns promise.getFuture(). The Consumer then performs other
     *   work, and eventually (or immediately) called Future.get() or Future.release().
     *   Either call will block until the asynchronous operation is complete and the
     *   result in Future is available.
     */
    template<typename T>
    class Future : public Cancelable
    {
    public:
        typedef std::function<void(const T&)> Callback;

    private:
        // internal structure to track referenced to the result
        struct Container {
            Container() { }
            Container(const T& obj) { set(obj); }
            void set(const T& obj) { _obj = std::move(obj); }
            T _obj;
            const T& obj() const { return _obj; }
            std::vector<Callback> _callbacks;
            std::mutex _callbacksMutex;
        };

    public:
        //! Blank CTOR
        Future() {
            _ev = std::make_shared<Event>();
            _shared = std::make_shared<Container>();
        }

        Future(const std::string& name) {
            _ev = std::make_shared<Event>(name);
            _shared = std::make_shared<Container>();
        }

        //! Copy CTOR
        Future(const Future& rhs) :
            _ev(rhs._ev),
            _shared(rhs._shared) { }

        Future<T>& operator = (const Future<T>& rhs) {
            _ev = rhs._ev;
            _shared = rhs._shared;
            return *this;
        }

        //! True if the promise was resolved and a result if available.
        bool isAvailable() const {
            return _ev->isSet();
        }

        //! True if the Promise that generated this Future no longer exists
        //! and the Promise was never resolved.
        bool isAbandoned() const {
            return !isAvailable() && _shared.use_count() == 1;
        }

        bool isCanceled() const override {
            return isAbandoned();
        }

        //! The result value; blocks until it is available (or abandonded) and then returns it.
        const T& get() {
            while (!_ev->wait(1000u))
                if (isAbandoned())
                    break;
            return _shared->obj();
        }

        const T& get(const Cancelable* cancelable) {
            while(!_ev->wait(1000u)) {
                if (isAbandoned()) 
                    break;
                if (cancelable && cancelable->isCanceled()) 
                    break;
            }
            return _shared->obj();
        }

        Future<T>& then(std::function<void(T&)>& func) {
            std::unique_lock<std::mutex> lock(_shared->_callbacksMutex);
            if (_ev->isSet()) {
                if (_shared->empty() == false)
                    func(_shared->_obj());
            }
            else
                _shared->_callbacks.push_back(func);
            return *this;
        }

        //! Release reference to a promise, resetting this future to its default state
        void abandon()
        {
            _shared = std::make_shared<Container>();
            _ev->reset();
        }

    private:
        std::shared_ptr<Event> _ev;
        std::shared_ptr<Container> _shared;
        template<typename U> friend class Promise;
    };

    /**
     * Promise is the producer-side interface to an asynchronous operation.
     *
     * Usage: The code that initiates an asychronous operation creates a Promise
     *   object, dispatches the asynchronous code, and immediately returns
     *   Promise.getFuture(). The caller can then call future.get() to block until
     *   the result is available.
     */
    template<typename T>
    class Promise : public Cancelable
    {
    public:
        Promise() { }

        Promise(const std::string& name) : _future(name) { }

        //! This promise's future result.
        Future<T> getFuture() const { return _future; }

        //! Resolve (fulfill) the promise with the provided result value.
        void resolve(const T& value) {
            _future._shared->set(value);
            {
                std::unique_lock<std::mutex> lock(_future._shared->_callbacksMutex);
                for(auto& f : _future._shared->_callbacks)
                    f(value);
            }
            _future._ev->set();
        }

        //! Resolve (fulfill) the promise with a default result.
        void resolve() {
            _future._ev->set();
        }

        //! True if the promise is resolved and the Future holds a valid result.
        bool isResolved() const {
            return _future._ev->isSet();
        }

        //! True is there are no Future objects waiting on this Promise.
        bool isAbandoned() const {
            return _future._shared.use_count() == 1;
        }

        bool isCanceled() const override {
            return isAbandoned();
        }

    private:
        Future<T> _future;
    };

    /**
     * Convenience base class for representing a Result object that may be
     * synchronous or asynchronous, depending on which constructor you use.
     */
    template<typename T>
    class FutureResult
    {
    public:
        bool isReady() const { 
            return _future.isAvailable() || _future.isAbandoned();
        }

    protected:
        //! Asynchronous constructor
        FutureResult(Future<T> f) : _future(f) { }

        //! Immediate synchronous resolve constructor
        FutureResult(const T& data) {
            Promise<T> p;
            _future = p.getFuture();
            p.resolve(data);
        }

        Future<T> _future;
    };


    /**
    * Mutex that locks on a per-object basis
    */
    template<typename T>
    class Gate
    {
    public:
        Gate() { }

        Gate(const std::string& name) : _m(name) { }

        inline void lock(T key) {
            std::unique_lock<Mutex> lock(_m);
            while(_users[key] > 0)
                _unlocked.wait(lock);
            ++_users[key];
        }

        inline void unlock(T key) {
            std::unique_lock<Mutex> lock(_m);
            --_users[key];
            if (_users[key] == 0) {
                _users.erase(key);
                _unlocked.notify_all();
            }
        }

        inline void setName(const std::string& name) {
            _m.setName(name);
        }

    private:
        Mutex _m;
        std::condition_variable_any _unlocked;
        std::unordered_map<T, int> _users;
    };

    template<typename T>
    struct ScopedGate {
        Gate<T>& _gate;
        T _key;
        ScopedGate(Gate<T>& gate, T key) : _gate(gate), _key(key) { _gate.lock(key); }
        ~ScopedGate() { _gate.unlock(_key); }
    };

    /**
     * Mutex that allows many simultaneous readers but only one writer
     */
    template<typename T>
    class ReadWrite
    {
    public:
        ReadWrite() :
            _readers(0u), _writers(0u) { }

        ReadWrite(const std::string& name) :
            _m(name), _readers(0u), _writers(0u) { }

        void read_lock() {
            std::unique_lock<T> lock(_m);
            while (_writers > 0)
                _unlocked.wait(lock);
            ++_readers;
        }

        void read_unlock() {
            std::unique_lock<T> lock(_m);
            --_readers;
            if (_readers == 0)
                _unlocked.notify_one();
        }

        void write_lock() {
            std::unique_lock<T> lock(_m);
            while (_writers > 0 || _readers > 0)
                _unlocked.wait(lock);
            ++_writers;
        }

        void write_unlock() {
            std::unique_lock<T> lock(_m);
            _writers = 0;
            _unlocked.notify_one();
        }

        void setName(const std::string& name) {
            _m.setName(name);
        }

    private:
        T _m;
        std::condition_variable_any _unlocked;
        unsigned _writers;
        unsigned _readers;
    };

    template<typename T>
    struct ScopedWrite {
        ScopedWrite( ReadWrite<T>& lock ) : _lock(lock) { _lock.write_lock(); }
        ~ScopedWrite() { _lock.write_unlock(); }
    private:
        ReadWrite<T>& _lock;
    };

    template<typename T>
    struct ScopedRead {
        ScopedRead( ReadWrite<T>& lock ) : _lock(lock) { _lock.read_lock(); }
        ~ScopedRead() { _lock.read_unlock(); }
    private:
        ReadWrite<T>& _lock;
    };

    typedef ReadWrite<Mutex> ReadWriteMutex;
    typedef ReadWrite<RecursiveMutex> ReadWriteRecursiveMutex;
    typedef ScopedRead<Mutex> ScopedReadLock;
    typedef ScopedWrite<Mutex> ScopedWriteLock;
    typedef ScopedRead<RecursiveMutex> ScopedRecursiveReadLock;
    typedef ScopedWrite<RecursiveMutex> ScopedRecursiveWriteLock;

    /**
     * A ThreadPool that contains a work queue and one or more
     * threads that process the operations on the queue.
     * @deprecated Use Job/JobArena instead
     */
    class OSGEARTH_EXPORT ThreadPool : public osg::Referenced
    {
    public:
        //! Allocate a new pool with "numThreads" threads.
        ThreadPool(
            unsigned numThreads =2u);

        //! Allocate a new pool with "numThreads" threads
        ThreadPool(
            const std::string& name,
            unsigned numThreads =2u);

        //! Destroy
        ~ThreadPool();

        //! Run an asynchronous operation in this thread pool.
        void run(osg::Operation*);

        //! How many operations are queued up?
        unsigned getNumOperationsInQueue() const;

        //! Store/retrieve thread pool stored in an options structure
        void put(class osgDB::Options*);
        static osg::ref_ptr<ThreadPool> get(const class osgDB::Options*);

    private:
        void startThreads();
        void stopThreads();

        // thread name
        std::string _name;

        // queued operations to run asynchronously
        typedef std::queue<osg::ref_ptr<osg::Operation> > Queue;
        Queue _queue;
        // protect access to the queue
        Mutex _queueMutex;
        // number of concurrent threads in the pool
        unsigned int _numThreads;
        // thread waiter block
        std::condition_variable_any _block;
        // set to true when threads should exit
        bool _done;
        // threads in the pool
        std::vector<std::thread> _threads;
    };

    /**
     * Simple convenience construct to make another type "lockable"
     * as long as it has a default constructor
     */
    template<typename T>
    struct Mutexed : public T, public BasicLockable {
        Mutexed() : T() { }
        Mutexed(const std::string& name) : _lockable_mutex(name), T() { }
        void setName(const std::string& name) { _lockable_mutex.setName(name); }
        void lock() { _lockable_mutex.lock(); }
        void lock() const { _lockable_mutex.lock(); }
        void unlock() { _lockable_mutex.unlock(); }
        void unlock() const { _lockable_mutex.unlock(); }
        Mutex& mutex() const { return _lockable_mutex; }
    private:
        mutable Mutex _lockable_mutex;
    };


    /**
     * Simple atomic counter that increments an atomic
     * when entering a scope and decrements it upon exiting the scope
     */
    struct ScopedAtomicCounter
    {
        std::atomic_int& _a;
        ScopedAtomicCounter(std::atomic_int& a) : _a(a) { ++_a; }
        ~ScopedAtomicCounter() { --_a; }
    };

    //! Sets the name of the curent thread
    extern OSGEARTH_EXPORT void setThreadName(const std::string& name);

    //! Sets the thread name with details when scoped
    struct ScopedThreadName
    {
        std::string _base;
        ScopedThreadName(const std::string& base, const std::string& detail) : 
            _base(base)
        {
            setThreadName(base + "(" + detail + ")");
        }
        ~ScopedThreadName()
        {
            setThreadName(_base);
        }
    };

    class JobArena;

    /**
     * API for scheduling a task to run in the background.
     *
     * Example usage:
     *
     *   int a = 10, b = 20;
     *
     *   Future<int> result = Job<int>::dispatch(
     *      "My Arena",
     *      [a, b](Cancelable* progress) {
     *          return (a + b);
     *      }
     *   );
     *
     *   // later...
     *
     *   if (result.isAvailable()) {
     *       std::cout << "Answer = " << result.get() << std::endl;
     *   }
     *   else if (result.isAbandoned()) {
     *       // task was canceled
     *   }
     */
    template<typename RESULT_TYPE>
    class Job
    {
    public:
        //! Result of a dispatched Job
        typedef Future<RESULT_TYPE> Result;

        //! Function signature for a job's operation method
        typedef std::function<RESULT_TYPE(Cancelable*)> Function;

        //! Dispatch a background job and return the future-result.
        //! @function Function to execute asynchronously.
        static Result dispatch(
            const Function& function);

        //! Dispatch a background job and return the future-result.
        //! @param arena Named arena in which to run the job.
        //! @function Function to execute asynchronously.
        static Result dispatch(
            const std::string& arena,
            const Function& function);

        //! Dispatch a background job and return the future-result.
        //! @param arena Arena in which to run the job.
        //! @function Function to execute asynchronously.
        static Result dispatch(
            JobArena& arena,
            const Function& function);

        //! Dispatch a background job and forget about it.
        //! @function Function to execute asynchronously.
        static void dispatchAndForget(
            const Function& function);

        //! Dispatch a background job and forget about it.
        //! @param arena Named arena in which to run the job.
        //! @function Function to execute asynchronously.
        static void dispatchAndForget(
            const std::string& arena,
            const Function& function);

        //! Dispatch a background job and forget about it.
        //! @param arena Arena in which to run the job.
        //! @function Function to execute asynchronously.
        static void dispatchAndForget(
            JobArena& arena,
            const Function& function);
    };

    /**
     * Schedules asynchronous tasks on a thread pool.
     * You usually don't need to use this class directly.
     * Use Job::schedule() to queue a new job.
     */
    class OSGEARTH_EXPORT JobArena
    {
    public:
        //! Construct a new JobArena
        JobArena(
            const std::string& name,
            unsigned concurrency = 2u);

        //! Destroy
        ~JobArena();

        //! Sets the concurrency of a named arena
        static void setSize(
            const std::string& name,
            unsigned numThreads);

        //! Returns the number of queued operations in the arena
        std::size_t queueSize() const;

        //! Returns the number of queued operations in the named arena
        static std::size_t queueSize(const std::string& arenaName);

        //! Access a named arena
        static JobArena* arena(const std::string& name);

        //! Schedule an asynchronous task on this arena.
        //! Consider using the Job<> interface before using this method directly.
        //! @param delegate Function to execute asynhronously
        void dispatch(std::function<void()>& job);

        //! Name of the arena to use when none is specified
        static const std::string& defaultArenaName();

    private:

        void startThreads();

        void stopThreads();

        // pool name
        std::string _name;
        // queued operations to run asynchronously
        typedef std::deque<std::function<void()>> Queue;
        Queue _queue;
        // protect access to the queue
        mutable Mutex _queueMutex;
        // number of concurrent threads in the pool
        unsigned _numThreads;
        // thread waiter block
        std::condition_variable_any _block;
        // set to true when threads should exit
        bool _done;
        // threads in the pool
        std::vector<std::thread> _threads;

        static Mutex _arenas_mutex;
        static std::unordered_map<std::string, unsigned> _arenaSizes;
        static std::unordered_map<std::string, std::shared_ptr<JobArena>> _arenas;
        static std::string _defaultArenaName;
    };

    template<typename RESULT_TYPE>
    Future<RESULT_TYPE>
    Job<RESULT_TYPE>::dispatch(const Function& function)
    {
        return dispatch(JobArena::defaultArenaName(), function);
    }

    template<typename RESULT_TYPE>
    Future<RESULT_TYPE>
    Job<RESULT_TYPE>::dispatch(
        const std::string& arenaName,
        const Function& function)
    {
        JobArena* arena = JobArena::arena(arenaName);
        return dispatch(*arena, function);
    }


    template<typename RESULT_TYPE>
    Future<RESULT_TYPE>
    Job<RESULT_TYPE>::dispatch(
        JobArena& arena,
        const Function& function)
    {
        Promise<RESULT_TYPE> promise;
        Future<RESULT_TYPE> future = promise.getFuture();

        std::function<void()> delegate = [function, promise]() mutable
        {
            if (!promise.isAbandoned())
            {
                promise.resolve(function(&promise));
            }
        };
        arena.dispatch(delegate);
        return std::move(future);
    }

    template<typename RESULT_TYPE>
    void Job<RESULT_TYPE>::dispatchAndForget(
        const Job::Function& function)
    {
        dispatchAndForget(JobArena::defaultArenaName(), function);
    }

    template<typename RESULT_TYPE>
    void Job<RESULT_TYPE>::dispatchAndForget(
        const std::string& arenaName,
        const Job::Function& function)
    {
        JobArena* arena = JobArena::arena(arenaName);
        dispatchAndForget(arena, function);
    }

    template<typename RESULT_TYPE>
    void Job<RESULT_TYPE>::dispatchAndForget(
        JobArena& arena,
        const Job::Function& function)
    {
        std::function<void()> delegate = [function]() mutable
        {
            function(nullptr);
        };
        arena.dispatch(delegate);
    }

} } // namepsace osgEarth::Threading

#define OE_THREAD_NAME(name) osgEarth::Threading::setThreadName(name);

#define OE_SCOPED_THREAD_NAME(base,name) osgEarth::Threading::ScopedThreadName _scoped_threadName(base,name);

#endif // OSGEARTH_THREADING_UTILS_H
